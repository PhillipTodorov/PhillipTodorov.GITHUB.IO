{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "7-intro-to-the-functional-API.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PhillipTodorov/PhillipTodorov.GITHUB.IO/blob/master/7_intro_to_the_functional_API.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tUznD9FVvTsP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#functional api implementation of a two-input question-answering model\n",
        "from keras.models import Model\n",
        "from keras import layers\n",
        "from keras import Input\n",
        "\n",
        "text_vocabulary_size = 10000\n",
        "question_vocabulary_size = 10000\n",
        "answer_vocabulary_size = 500\n",
        "\n",
        "text_input = Input(shape=(None,), dtype='int32', name='text')\n",
        "\n",
        "embedded_text = layers.Embedding(64, text_vocabulary_size)(text_input)\n",
        "\n",
        "encoded_text = layers.LSTM(32)(embedded_text)\n",
        "\n",
        "question_input = Input(shape=(None,), dtype='int32', name='question')\n",
        "\n",
        "embedded_question = layers.Embedding(32, question_vocabulary_size)(question_input)\n",
        "\n",
        "encoded_question = layers.LSTM(16)(embedded_question)\n",
        "\n",
        "concatenated = layers.concatenate([encoded_text, encoded_question], axis=-1)\n",
        "\n",
        "answer = layers.Dense(answer_vocabulary_size, activation='softmax')(concatenated)\n",
        "\n",
        "model = Model([text_input, question_input], answer)\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['acc'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHT_XHL91PVz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#feeding data to a multi-input model\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "num_samples = 1000\n",
        "max_length = 100\n",
        "\n",
        "text = np.random.randint(1, text_vocabulary_size, size=(num_samples, max_length))\n",
        "\n",
        "question = np.random.randint(1, question_vocabulary_size, size=(num_samples, max_length))\n",
        "\n",
        "answers = np.random.randint(0, 1, size=(num_samples, answer_vocabulary_size))\n",
        "\n",
        "model.fit([text,question], answers, epochs=10, batch_size=128)\n",
        "\n",
        "model.fit({'text': text, 'question': question}, answers, epochs=10, batch_size=128)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L7e-3u1rTZEK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#functional api implementation of a three-output model\n",
        "\n",
        "from keras import layers\n",
        "from keras import Input \n",
        "from keras.models import Model\n",
        "\n",
        "vocabulary_size = 50000\n",
        "num_income_groups = 10\n",
        "\n",
        "posts_input = Input(shape=(None,), dtype='int32', name='posts')\n",
        "embedded_posts = layers.Embedding(256, vocabulary_size)(posts_input)\n",
        "x = layers.Conv1D(128, 5, activation='relu')(embedded_posts)\n",
        "x = layers.MaxPooling1D(5)(x)\n",
        "x = layers.Conv1D(256, 5, activation='relu')(x)\n",
        "x = layers.Conv1D(256, 5, activation='relu')(x)\n",
        "x = layers.MaxPooling1D(5)(x)\n",
        "x = layers.Conv1D(256, 5, activation='relu')(x)\n",
        "x = layers.Conv1D(256, 5, activation='relu')(x)\n",
        "x = layers.GlobalMaxPooling1D()(x)\n",
        "x = layers.Dense(128, activation='relu')(x)\n",
        "\n",
        "age_prediction = layers.Dense(1, name='age')(x)\n",
        "income_prediction = layers.Dense(num_income_groups, activation='softmax', name='income')(x)\n",
        "gender_prediction = layers.Dense(1, activation='sigmoid', name='gender')(x)\n",
        "\n",
        "model = Model(posts_input, [age_prediction, income_prediction, gender_prediction])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7glAiCU3RNxb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#compilation option of a multi-output model: multiple losses\n",
        "\n",
        "model.compile(optimizer='rmsprop', loss=['mse', 'categorical_crossentropy', 'binary_crossentropy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Bx8FrgCROOH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#compilation option of a multi-output model: loss weighting\n",
        "\n",
        "model.compile(optimizer='rmsprop', loss=['mse', 'categorical_crossentropy', 'binary_crossentropy'], loss_weights=[0.25, 1., 10.])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zYEZKZx9PXLb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#feeding data to a multi-output model\n",
        "\n",
        "model.fit(posts, [age_targets, income_targets, gender_targets], epochs=10, batch_size=64)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88wrfcxNcUda",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}